GITHUB_TOKEN=<GITHUB_TOKEN>
STREAM=True
USE_SYSTEM_PROMPT=True

## System Prompt for `NousResearch/DeepHermes-3-Llama-3-8B-Preview`
SYSTEM_PROMPT="You are a deep thinking AI, you may use extremely long chains of thought to deeply consider the problem and deliberate with yourself via systematic reasoning processes to help come to a correct solution prior to answering. You should enclose your thoughts and internal monologue inside <think> </think> tags, and then provide your solution or response to the problem."

## LLM Provider Configuration
## Set MODEL_PROVIDER to select which LLM provider to use (openrouter or groq)
MODEL_PROVIDER=openrouter

## Groq Configuration
## To use Groq, set MODEL_PROVIDER=groq and provide your Groq API key
GROQ_API_KEY=<GROQ_API_KEY>
# GROQ_MODEL=llama-3.1-8b-instant
GROQ_MODEL=qwen-qwq-32b
# GROQ_MODEL=deepseek-r1-distill-llama-70b
# GROQ_MODEL=llama-3.3-70b-versatile

## OpenRouter Configuration
OPENROUTER_API_KEY=<OPENROUTER_API_KEY>
OPENROUTER_MODEL=nousresearch/deephermes-3-llama-3-8b-preview:free
# OPENROUTER_MODEL=qwen/qwen2.5-vl-72b-instruct:free
# OPENROUTER_MODEL=qwen/qwen3-4b:free
# OPENROUTER_MODEL=microsoft/mai-ds-r1:free
# OPENROUTER_MODEL=tngtech/deepseek-r1t-chimera:free
# OPENROUTER_MODEL=nvidia/llama-3.3-nemotron-super-49b-v1
# OPENROUTER_MODEL=openai/gpt-4.1-nano
# OPENROUTER_MODEL=openai/gpt-4.1-mini
# OPENROUTER_MODEL=openai/gpt-4.1
# OPENROUTER_MODEL=mistralai/mistral-medium-3
# OPENROUTER_MODEL=openai/o4-mini-high
# OPENROUTER_MODEL=google/gemini-2.5-pro-preview
# OPENROUTER_MODEL=anthropic/claude-3.7-sonnet:thinking
# OPENROUTER_MODEL=anthropic/claude-3.7-sonnet

## Context Length Configuration
# Specify the context length of your model (defaults to 8192 if not specified)
# This will be used to reserve 20% for model responses and limit input to 80%
CURRENT_MODEL_CONTEXT_LENGTH=8192